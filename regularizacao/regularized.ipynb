{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNX0kWQRjMAomYnYNb0h7LM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/witoriamanuely/aprendizagem_de_maquina_2022.2/blob/master/regularizacao/regularized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DQMjzIqN3NQa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import skew\n",
        "from scipy.stats.stats import pearsonr\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "knn = KNeighborsRegressor(n_neighbors=7)\n",
        "%config InlineBackend.figure_format = 'png' #set 'png' here when working on notebook\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv ('/content/drive/MyDrive/mestrado/2022.2/aprendizagem_de_maquina_2022.2/2olab/eleicoes_2006_a_2010.csv')\n",
        "df_2014 = pd.read_csv ('/content/drive/MyDrive/mestrado/2022.2/aprendizagem_de_maquina_2022.2/2olab/eleicoes_2014.csv')"
      ],
      "metadata": {
        "id": "HyvaGq0n32GW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aa31186-b8bd-4c03-812d-2f96b75784b6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1 - Analisar as distribuições das variáveis para ver se estão enviesadas e precisam de correção; tratamento de valores ausentes, variáveis categóricas e normalização, quando for o caso.\n",
        "**Abaixo temos a retiradas dos NaN encontrados no meio dos dados, também há a separação dos dados de treino para os dados do ano de 2006 e os dados de teste para os dados do ano de 2010**"
      ],
      "metadata": {
        "id": "XaicmniEUb2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Concatena os dados entre dos anos de 2006+2010 e 2014\n",
        "df_all = pd.concat([df, df_2014], ignore_index=True)\n",
        "\n",
        "#Retirando variáveis categoricas\n",
        "df_all = df_all.drop(columns=[\"sequencial_candidato\", \"nome\", \"cargo\"])\n",
        "\n",
        "# Normaliza todos os valores\n",
        "df_all = df_all.fillna(df_all.mean().round(1))\n",
        "anos = df_all[\"ano\"]\n",
        "index = df_all.dtypes[df_all.dtypes != \"object\"].index\n",
        "\n",
        "df_all[index] = np.log1p(df_all[index])\n",
        "df_all = pd.get_dummies(df_all)\n",
        "\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "df_all[index] = scaler.fit_transform(df_all[index])\n",
        "df_all[\"ano\"] = anos\n",
        "\n",
        "\n",
        "# Separa os dados de treino e teste\n",
        "x_2010 = df_all[df_all[\"ano\"] == 2010]\n",
        "x_2006 = df_all[df_all[\"ano\"] == 2006]\n",
        "x_train = pd.concat([x_2010, x_2006], ignore_index=True)\n",
        "x_test = df_all[df_all[\"ano\"] == 2014]\n",
        "\n",
        "# Separa os valores que devem ser feito a predição\n",
        "y_train = x_train.votos\n",
        "y_test = x_test.votos\n",
        "\n",
        "# Remove valores dos dados de treino e validação\n",
        "x_train = x_train.drop(columns=[\"ano\",\"votos\"])\n",
        "x_test = x_test.drop(columns=[\"ano\",\"votos\"])\n"
      ],
      "metadata": {
        "id": "rhFLMLsB54zP",
        "outputId": "44b39ce8-4ed3-40ea-a67c-1f4dc9c31c8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.2 Construir modelos de regressão com (ridge e lasso) "
      ],
      "metadata": {
        "id": "7gENdHKSWEre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelos abaixo:\n",
        "model_lasso = LassoCV(cv=10).fit(x_train, y_train)\n",
        "model_ridge = Ridge(alpha=1).fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "EIN-qc6lWObr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c63c40-9282-4799-d25e-a7b02ee82f57"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:644: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.019844782505980874, tolerance: 0.012582000650803364\n",
            "  positive,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:644: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01959224869234788, tolerance: 0.01275325219683901\n",
            "  positive,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:644: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.016532360674752056, tolerance: 0.012654523221707134\n",
            "  positive,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abaixo temos a acuracia de cada modelo:"
      ],
      "metadata": {
        "id": "3Qg1_mPMFfph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Score de treino em Lasso', model_lasso.score(x_train, y_train))\n",
        "print('Score de Validação em Lasso', model_lasso.score(x_test, y_test))\n",
        "\n",
        "print('Score de treino em Ridge', model_ridge.score(x_train, y_train))\n",
        "print('Score de Validação em Ridge', model_ridge.score(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aqggKJn9PO8",
        "outputId": "8684357e-9ae6-4246-cb9a-0dd7e00673a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score de treino em Lasso 0.7727459383277528\n",
            "Score de Validação em Lasso -0.19053431083605776\n",
            "Score de treino em Ridge 0.7789868208122119\n",
            "Score de Validação em Ridge -0.2788891372527771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.3 considerar outros modelos ainda não vistos em sala de sua escolha (e.g. SVR, Regression Trees, KNN e Random Florests).\n",
        "\n",
        "Nesse caso escolhi o KNN como outro modelo."
      ],
      "metadata": {
        "id": "qj36YB17Fl8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_knn = knn.fit(x_train, y_train)\n",
        "print('Score de treino em KNN', model_knn.score(x_train, y_train))\n",
        "print('Score de Validação em KNN', model_knn.score(x_test, y_test))"
      ],
      "metadata": {
        "id": "iKrgX_sNQGyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.5 Plotar os resíduos versus predições e analisar se esses plots representam bons indícios da adequabilidade dos modelos a esse problema."
      ],
      "metadata": {
        "id": "mgSVpSHsQRIG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Abaixo temos a comparação da Predição e dos valores reais no modelo Lasso"
      ],
      "metadata": {
        "id": "yHTIzaMFOtKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_results = model_ridge.predict(x_test)\n",
        "plt.subplots(figsize=(18, 10))\n",
        "plt.subplot(211)\n",
        "plt.title(\"Predição - Lasso\")\n",
        "plt.plot(range(len(lasso_results)), lasso_results)\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.title(\"Valores Reais\")\n",
        "plt.plot(range(len(y_test)), y_test)"
      ],
      "metadata": {
        "id": "53XHQ3K0FLXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coef = pd.Series(model_lasso.coef_, index = x_train.columns)\n",
        "print(\"Lasso retirou \" + str(sum(coef != 0)) + \" variáveis e eliminou outras \" +  str(sum(coef == 0)) + \" variáveis\")\n",
        "imp_coef = pd.concat([coef.sort_values().head(10),\n",
        "                     coef.sort_values().tail(10)])\n",
        "matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
        "imp_coef.plot(kind = \"barh\")\n",
        "plt.title(\"Coeficientes no modelo Lasso\")"
      ],
      "metadata": {
        "id": "S0tD7VWQQ633"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
        "preds = pd.DataFrame({\"preds\":model_lasso.predict(x_train), \"true\":y_train})\n",
        "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
        "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")"
      ],
      "metadata": {
        "id": "LKWkWoloRAWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Abaixo temos a comparação da Predição e dos valores reais no modelo Ridge"
      ],
      "metadata": {
        "id": "32QjKYyRO4mX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ridge_results = model_ridge.predict(x_test)\n",
        "plt.subplots(figsize=(18, 10))\n",
        "plt.subplot(211)\n",
        "plt.title(\"Predição - Ridge\")\n",
        "plt.plot(range(len(ridge_results)), ridge_results)\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.title(\"Valores Reais\")\n",
        "plt.plot(range(len(y_test)), y_test)"
      ],
      "metadata": {
        "id": "er-QjZL39Q18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coef = pd.Series(model_ridge.coef_, index = x_train.columns)\n",
        "print(\"Ridge retirou \" + str(sum(coef != 0)) + \" variáveis e eliminou outras \" +  str(sum(coef == 0)) + \" variáveis\")\n",
        "imp_coef = pd.concat([coef.sort_values().head(10),\n",
        "                     coef.sort_values().tail(10)])\n",
        "matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
        "imp_coef.plot(kind = \"barh\")\n",
        "plt.title(\"Coeficientes no modelo Ridge\")"
      ],
      "metadata": {
        "id": "RYxHPJZeRH1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
        "preds = pd.DataFrame({\"preds\":model_ridge.predict(x_train), \"true\":y_train})\n",
        "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
        "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")"
      ],
      "metadata": {
        "id": "_nC9USlmRxKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Abaixo temos a comparação da Predição e dos valores reais no modelo KNN"
      ],
      "metadata": {
        "id": "hBXYUkk3O9tD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn_results = model_knn.predict(x_test)\n",
        "plt.subplots(figsize=(18, 10))\n",
        "plt.subplot(211)\n",
        "plt.title(\"Predição - KNN\")\n",
        "plt.plot(range(len(knn_results)), knn_results)\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.title(\"Valores Reais\")\n",
        "plt.plot(range(len(y_test)), y_test)"
      ],
      "metadata": {
        "id": "RSJebjuUO_TJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
        "preds = pd.DataFrame({\"preds\":model_knn.predict(x_train), \"true\":y_train})\n",
        "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
        "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")"
      ],
      "metadata": {
        "id": "wPFY3XPLHuVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RESPOSTA - 2.5: Tanto o ranking de Lasso como Ridge são semelhantes, porém  Lasso eliminou mais coeficientes que Ridge, enquanto Ridge escolheu mais coeficientes que o Lasso. Não teve como plotar o ranking do KNN devido a lib do KNeighborsRegressor não possuir o atributo coef_. Foi possível ver que os modelos possuem dados semelhantes uns aos outros e também próximos aos dados de teste. \n"
      ],
      "metadata": {
        "id": "7qSSjSljUsW-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 Dentre os modelos avaliados, qual foi o que deu o melhor resultado nos dados de 2014 em termos de RMSE? Justifique bem sua resposta."
      ],
      "metadata": {
        "id": "HbpoVFQgSArP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse_cv(model):\n",
        "  rmse= np.sqrt(-cross_val_score(model, x_train, y_train, scoring=\"neg_mean_squared_error\"))\n",
        "  return(rmse)\n",
        "#print(\"Lasso RMSE\" + rmse_cv(model_lasso))\n",
        "#print(\"Ridge RMSE\" + rmse_cv(model_ridge))\n",
        "#print(\"KNN RMSE\"+ rmse_cv(model_knn))"
      ],
      "metadata": {
        "id": "4kpIzCi2fNo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abaixo temos um plot do resultado final de treino e teste, com isso pode-se concluir que embora.... "
      ],
      "metadata": {
        "id": "W7rF6S2TVu2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "dtrain = xgb.DMatrix(x_train, label = y_train)\n",
        "dtest = xgb.DMatrix(x_test)\n",
        "\n",
        "params = {\"max_depth\":2, \"eta\":0.1}\n",
        "model = xgb.cv(params, dtrain,  num_boost_round=500, early_stopping_rounds=100)\n",
        "model.loc[30:,[\"test-rmse-mean\", \"train-rmse-mean\"]].plot()"
      ],
      "metadata": {
        "id": "OgLx-wBdVteV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install nbconvert\n",
        "!jupyter nbconvert --to html Previsao_Eleicao_Deputados.ipynb"
      ],
      "metadata": {
        "id": "KiGuMXpiXtBx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}